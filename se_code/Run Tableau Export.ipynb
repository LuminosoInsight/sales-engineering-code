{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Lumi data...\n",
      "Creating doc table...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/se_code-0.1-py3.6.egg/se_code/fuzzy_logic.py:38: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file doc_table.csv.\n",
      "Writing to file xref_table.csv.\n",
      "Creating themes table...\n",
      "Writing to file themes_table.csv.\n",
      "Creating subset key terms table...\n"
     ]
    }
   ],
   "source": [
    "#%run tableau_export.py r85b548r prnzh4tp\n",
    "%run tableau_export.py demo pr527dgq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run tableau_export.py d53m338v prkpg9nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SEPHORA\n",
    "%run tableau_export.py h82y756m prdc54bx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = [(1,1), (2,3), (3,2)]\n",
    "arr = sorted(arr, key = lambda a:a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from luminoso_api import LuminosoClient\n",
    "from pack64 import unpack64\n",
    "import run_voting_classifier # need accuracy/coverage chart\n",
    "from conjunctions_disjunctions import get_new_results\n",
    "from subset_key_terms import subset_key_terms\n",
    "from scipy.stats import linregress\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client, docs, topics, terms, subsets, drivers, skt, themes = pull_lumi_data('d53m338v', 'pr5cxsm3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_trends_table(terms, topics, docs):\n",
    "    term_vecs = np.asarray([unpack64(t['vector']) for t in terms])\n",
    "    concept_list = [t['text'] for t in terms]\n",
    "\n",
    "    dated_docs = [d for d in docs if 'date' in d]\n",
    "    dated_docs.sort(key = lambda k: k['date'])\n",
    "    dates = np.asarray([[datetime.datetime.fromtimestamp(int(d['date'])).strftime('%Y-%m-%d %H:%M:%S')] for d in dated_docs])\n",
    "\n",
    "    doc_vecs = np.asarray([unpack64(t['vector']) for t in dated_docs])\n",
    "    results = np.dot(term_vecs, np.transpose(doc_vecs))\n",
    "    results = np.transpose(results)\n",
    "    idx = [[x] for x in range(0, len(results))]\n",
    "    results = np.hstack((idx, results))\n",
    "    \n",
    "    headers = ['Date','Index']\n",
    "    headers.extend(concept_list)\n",
    "    \n",
    "    tenth = int(.9 * len(results))\n",
    "    quarter = int(.75 * len(results))\n",
    "    half = int(.5 * len(results))\n",
    "\n",
    "    slopes = [linregress(results[:,x+1],results[:,0])[0] for x in range(len(results[0])-1)]\n",
    "    slope_ranking = zip(concept_list, slopes)\n",
    "    slope_ranking = sorted(slope_ranking, key=lambda rank:rank[1])\n",
    "    slope_ranking = slope_ranking[::-1]\n",
    "    \n",
    "    tenth_slopes = [linregress(results[tenth:,x+1],results[tenth:,0])[0] for x in range(len(results[0]) - 1)]\n",
    "    tenth_slope_ranking = zip(concept_list, tenth_slopes)\n",
    "    tenth_slope_ranking = sorted(tenth_slope_ranking, key=lambda rank:rank[1])\n",
    "    tenth_slope_ranking = tenth_slope_ranking[::-1]\n",
    "    \n",
    "    quarter_slopes = [linregress(results[quarter:,x+1],results[quarter:,0])[0] for x in range(len(results[0]) - 1)]\n",
    "    quarter_slope_ranking = zip(concept_list, quarter_slopes)\n",
    "    quarter_slope_ranking = sorted(quarter_slope_ranking, key=lambda rank:rank[1])\n",
    "    quarter_slope_ranking = quarter_slope_ranking[::-1]\n",
    "    \n",
    "    half_slopes = [linregress(results[half:,x+1],results[half:,0])[0] for x in range(len(results[0]) - 1)]\n",
    "    half_slope_ranking = zip(concept_list, half_slopes)\n",
    "    half_slope_ranking = sorted(half_slope_ranking, key=lambda rank:rank[1])\n",
    "    half_slope_ranking = half_slope_ranking[::-1]\n",
    "    \n",
    "    results = np.hstack((dates, results))\n",
    "    #trends_table = [{key:value for key, value in zip(headers, r)} for r in results]\n",
    "    trends_table = []\n",
    "    for r in results:\n",
    "        dic = {}\n",
    "        for key, value in zip(header, r):\n",
    "            dic.update(key:value)\n",
    "        trends_table.append(dic)\n",
    "    trendingterms_table = [{'Term':term, \n",
    "                            'Slope':slope, \n",
    "                            'Rank':slope_ranking.index((term, slope)), \n",
    "                            'Short term slope':tenth_slope, \n",
    "                            'Short term rank':tenth_slope_ranking.index((term, tenth_slope)), \n",
    "                            'Medium term slope':quarter_slope,\n",
    "                            'Medium term rank':quarter_slope_ranking.index((term, quarter_slope)), \n",
    "                            'Half term slope':half_slope, \n",
    "                            'Half term rank':half_slope_ranking.index((term, half_slope))}\n",
    "                           for term, slope, tenth_slope, quarter_slope, half_slope in zip(concept_list, slopes, tenth_slopes, quarter_slopes, half_slopes)]\n",
    "\n",
    "    return trends_table, trendingterms_table, results\n",
    "\n",
    "#def create_prediction_table():\n",
    "    \n",
    "    \n",
    "#def create_pairings_table():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trends_table, trendingterms_table, results = create_trends_table(terms, topics, docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
